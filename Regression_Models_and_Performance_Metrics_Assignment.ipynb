{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Regression\n",
        "Models and Performance Metrics Assignment\n"
      ],
      "metadata": {
        "id": "4nF0cOvBTAcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 1 :-What is Simple Linear Regression (SLR)? Explain its purpose\n",
        "\n",
        "Answer:- Simple Linear Regression (SLR) is a statistical method used to study the relationship between one independent variable (X) and one dependent variable (Y). It assumes that the relationship between these two variables is linear, meaning it can be represented by a straight-line equation of the form Y = a + bX, where a is the intercept (the value of Y when X is zero) and b is the slope (the rate at which Y changes with respect to X). The main purpose of Simple Linear Regression is to predict the value of the dependent variable based on the given value of the independent variable and to understand how strongly and in what direction the two variables are related. It helps in identifying trends, measuring the impact of one variable on another, and making data-driven decisions. For example, it can be used to predict marks based on hours studied, sales based on advertising expenditure, or house prices based on size."
      ],
      "metadata": {
        "id": "lW14UStCTDbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 2 :- What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "Answer:- Simple Linear Regression (SLR) is based on several key assumptions to ensure that the model produces accurate and reliable results. First, it assumes linearity, meaning there must be a straight-line relationship between the independent variable (X) and the dependent variable (Y). Second, it assumes independence of errors, which means the residuals (differences between actual and predicted values) should not be related to each other. Third, it requires homoscedasticity, meaning the variance of the residuals should remain constant across all values of X; the spread of errors should be roughly the same throughout. Fourth, the model assumes normality of errors, meaning the residuals should be approximately normally distributed, especially for hypothesis testing and confidence interval estimation. These assumptions help ensure that the regression results are valid, unbiased, and statistically meaningful."
      ],
      "metadata": {
        "id": "w0FFvqaSTY28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 3 :- Write the mathematical equation for a simple linear regression model and\n",
        "explain each term\n",
        "\n",
        "Answer:- The mathematical equation for a Simple Linear Regression (SLR) model is:\n",
        "\n",
        "ùëå = ùõΩ0 + ùõΩ1X + ùúÄ\n",
        "\n",
        "\n",
        "In this equation, Y represents the dependent variable, which is the outcome or response we want to predict. X is the independent variable, also called the predictor, which is used to explain changes in Y. The term Œ≤‚ÇÄ (beta zero) is the intercept of the regression line; it represents the value of Y when X equals zero. The term Œ≤‚ÇÅ (beta one) is the slope of the regression line; it shows how much Y changes for a one-unit increase in X, indicating the strength and direction of the relationship. Finally, Œµ (epsilon) represents the error term or residual, which captures the difference between the actual observed value of Y and the value predicted by the model. This term accounts for other factors affecting Y that are not included in the model."
      ],
      "metadata": {
        "id": "VU4_HT2CTmgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 4 :- Provide a real-world example where simple linear regression can be\n",
        "applied.\n",
        "\n",
        "Answer:- A common real-world example of Simple Linear Regression is predicting house prices based on the size of the house. In this case, the independent variable (X) is the size of the house (in square feet), and the dependent variable (Y) is the price of the house. Generally, as the size of the house increases, the price also increases, showing a linear relationship. By collecting data on different houses and fitting a regression line, we can create an equation such as:\n",
        "\n",
        "Price=500000+2000√ó(Size)\n",
        "\n",
        "This means the base price of the house is ‚Çπ5,00,000, and for every additional square foot, the price increases by ‚Çπ2,000. Using this model, we can predict the price of a new house by simply knowing its size. This helps real estate companies, buyers, and sellers make informed financial decisions."
      ],
      "metadata": {
        "id": "ZcmoluUaUOQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 5 :- What is the method of least squares in linear regression?\n",
        "\n",
        "Answer:- The method of least squares is a technique used in linear regression to find the best-fitting straight line through a set of data points. The main idea of this method is to choose the regression line in such a way that the sum of the squares of the residuals (errors) is minimized. A residual is the difference between the actual observed value and the predicted value given by the regression line. Instead of minimizing the simple differences, we square them to ensure all errors are positive and to give more weight to larger errors.\n",
        "\n",
        "Mathematically, the method minimizes:\n",
        "\n",
        "‚àë(Yi‚Äã‚àíY^i‚Äã)2\n",
        "\n",
        "\n",
        "\t‚Äã\n",
        "\n",
        " where\n",
        "ùëå\n",
        "ùëñ\n",
        "Y\n",
        "i\n",
        "\t‚Äã\n",
        "\n",
        " is the actual value,\n",
        "ùëå\n",
        "^\n",
        "ùëñ\n",
        "Y\n",
        "^\n",
        "i\n",
        "\t‚Äã\n",
        "is the predicted value, and the squared differences are added for all observations. By minimizing this total squared error, we obtain the optimal values of the intercept and slope (Œ≤‚ÇÄ and Œ≤‚ÇÅ). This ensures that the regression line is the most accurate possible linear representation of the data."
      ],
      "metadata": {
        "id": "wLFXPJLxUpF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 6 :-  What is Logistic Regression? How does it differ from Linear Regression?\n",
        "\n",
        "Answer:-Logistic Regression is a supervised machine learning algorithm used for classification problems, especially when the dependent variable is binary, such as yes/no, pass/fail, or 0/1. Unlike Linear Regression, which predicts continuous numerical values, Logistic Regression predicts the probability that a given input belongs to a particular class. It uses a sigmoid (S-shaped) function to convert the linear combination of input variables into a probability value between 0 and 1. If the predicted probability is above a certain threshold (commonly 0.5), the model classifies the outcome as one class; otherwise, it classifies it as the other. The main difference between Logistic Regression and Linear Regression is that Linear Regression is used for predicting continuous outcomes and produces a straight-line equation, whereas Logistic Regression is used for classification tasks and produces probabilities using a sigmoid curve.\n"
      ],
      "metadata": {
        "id": "pCBTdIgvVQh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 7 :- Name and briefly describe three common evaluation metrics for regression\n",
        "models.\n",
        "\n",
        "Answer:- Three common evaluation metrics used for regression models are Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R¬≤).\n",
        "\n",
        "Mean Absolute Error (MAE) measures the average of the absolute differences between the actual and predicted values. It tells us, on average, how much the predictions deviate from the true values, without considering the direction of the error. Lower MAE indicates better model performance.\n",
        "\n",
        "Mean Squared Error (MSE) calculates the average of the squared differences between actual and predicted values. Because the errors are squared, larger errors are penalized more heavily, making MSE sensitive to outliers. A smaller MSE means the model fits the data better.\n",
        "\n",
        "R-squared (R¬≤), also known as the coefficient of determination, measures how well the independent variable explains the variation in the dependent variable. Its value ranges from 0 to 1, where values closer to 1 indicate that the model explains a large portion of the variance in the data."
      ],
      "metadata": {
        "id": "amzv2kA_V2WC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 8 :- What is the purpose of the R-squared metric in regression analysis?\n",
        "\n",
        "Answer:- The purpose of the R-squared (R¬≤) metric in regression analysis is to measure how well the regression model explains the variation in the dependent variable. In simple terms, it tells us how much of the total variability in the outcome variable is explained by the independent variable(s) in the model. The value of R¬≤ ranges from 0 to 1. An R¬≤ value close to 1 indicates that the model explains a large portion of the variation in the data, meaning the model fits the data well. On the other hand, an R¬≤ value close to 0 indicates that the model does not explain much of the variability, suggesting a poor fit. Therefore, R¬≤ helps in evaluating the goodness of fit of a regression model and comparing different models to determine which one better explains the data."
      ],
      "metadata": {
        "id": "7uxHSc1aWD-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques 9 :- Write Python code to fit a simple linear regression model using scikit-learn\n",
        "#and print the slope and intercept.\n",
        "\n",
        "\n",
        "# Import required libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample data (X must be 2D)\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# Create model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print slope and intercept\n",
        "print(\"Slope (Coefficient):\", model.coef_[0])\n",
        "print(\"Intercept:\", model.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOvIMjpsWggm",
        "outputId": "6b838dc9-98e0-401f-bc31-8db72164e7b7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (Coefficient): 0.6\n",
            "Intercept: 2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 10 :-  How do you interpret the coefficients in a simple linear regression model?\n",
        "\n",
        "Answer:-In a Simple Linear Regression model, the equation is written as:\n",
        "\n",
        "ùëå = ùõΩ0 + ùõΩ1x\n",
        "\n",
        "There are two main coefficients to interpret: the intercept (Œ≤‚ÇÄ) and the slope (Œ≤‚ÇÅ).\n",
        "\n",
        "The intercept (Œ≤‚ÇÄ) represents the value of the dependent variable (Y) when the independent variable (X) is equal to zero. It is the point where the regression line crosses the Y-axis. In practical terms, it shows the baseline value of Y when there is no effect from X.\n",
        "\n",
        "The slope (Œ≤‚ÇÅ) represents the change in the dependent variable (Y) for a one-unit increase in the independent variable (X). If the slope is positive, it means Y increases as X increases (positive relationship). If the slope is negative, it means Y decreases as X increases (negative relationship). The magnitude of the slope indicates how strong the effect of X is on Y.\n",
        "\n",
        "For example, if the regression equation is:\n",
        "\n",
        "Marks=30+5(Hours)\n",
        "\n",
        "The intercept 30 means a student scores 30 marks when studying 0 hours, and the slope 5 means that for every additional hour studied, marks increase by 5 points."
      ],
      "metadata": {
        "id": "JAcwREt9XMvT"
      }
    }
  ]
}